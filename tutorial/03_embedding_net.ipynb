{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning summary statistics with a neural net\n",
    "\n",
    "When doing simulation-based inference, it is very important to use well-chosen summary statistics for describing the data generated by the simulator. Very often, these statistics take into account previous domain knowledge. For instance, in the case of the Hodgkin-Huxley model from this [tutorial](https://www.mackelab.org/sbi/examples/00_HH_simulator/), the summary statistics are defined via the function defined in [here](https://github.com/mackelab/sbi/blob/86d9b07238f5a0176638fecdd5622694d92f2962/examples/HH_helper_functions.py#L159), which takes a 120 ms recording as input (a 12000-dimensional input vector) and outputs a 7-dimensional feature vector containing different statistical descriptors of the recording (e.g., number of spikes, average value, etc.). However, in some occasions, it might be of interest to actually **learn from the data** which summary statistics to use.\n",
    "\n",
    "`sbi` offers functionality to learn summary statistics from (potentially high-dimensional) simulation outputs with a neural network. In `sbi`, this neural network is referred to as `embedding_net`. If an `embedding_net` is specified, the simulation outputs are passed through the `embedding_net`, whose outputs are then passed to the neural density estimator. The parameters of the `embedding_net` are updated together with the parameters of the neural density estimator.\n",
    "\n",
    "NB: only `SNPE` and `SNRE` methods can use an `embedding_net` to learn summary statistics from simulation outputs. `SNLE` does not offer this functionality since the simulation outputs $x$ are the outputs of the neural density estimator in `SNLE`.\n",
    "\n",
    "In the example that follows, we illustrate a situation where the data points generated by the simulator model are high-dimensional (32 by 32 images) and we use a convolutional neural network as summary statistics extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you find the original version of this notebook at [https://github.com/mackelab/sbi/blob/main/tutorial/03_embedding_net.ipynb](https://github.com/mackelab/sbi/blob/main/tutorial/03_embedding_net.ipynb) in the `sbi` repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import all the packages required for running the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sbi import utils\n",
    "from sbi import inference\n",
    "import numpy as np\n",
    "\n",
    "# set seed for numpy and torch\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simulator model\n",
    "\n",
    "The simulator model that we consider has two parameters: $r$ and $\\theta$. On each run, it generates 100 two-dimensional points centered around $(r \\cos(\\theta), r \\sin(\\theta))$ and perturbed by a Gaussian noise with variance 0.01. Instead of simply outputting the $(x,y)$ coordinates of each data point, the model generates a grayscale image of the scattered points with dimensions 32 by 32. This image is further perturbed by an uniform noise with values betweeen 0 and 0.2. The code below defines such model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def simulator_model(parameter, return_points=False):\n",
    "    \"\"\" Simulator model with two-dimensional input parameter and 1024-dimensional output\n",
    "    \n",
    "    This simulator serves as a basic example for using a neural net for learning summary features. \n",
    "    It has only two input parameters but generates high-dimensional output vectors.\n",
    "    The data is generated as follows:\n",
    "        (-) Input:  parameter = [r, theta]\n",
    "        (1) Generate 100 two-dimensional points centered around (r cos(theta),r sin(theta))  \n",
    "            and perturbed by a Gaussian noise with variance 0.01\n",
    "        (2) Create a grayscale image I of the scattered points with dimensions 32 by 32\n",
    "        (3) Perturb I with an uniform noise with values betweeen 0 and 0.2\n",
    "        (-) Output: I \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array-like, shape (2)\n",
    "        The two input parameters of the model, ordered as [r, theta]\n",
    "    return_points : bool (default: False)\n",
    "        Whether the simulator should return the coordinates of the simulated data points as well\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    I: torch tensor, shape (1, 1024)    \n",
    "        Output flattened image\n",
    "    (optional) points: array-like, shape (100, 2)\n",
    "        Coordinates of the 2D simulated data points \n",
    "    \n",
    "    \"\"\"\n",
    "    r = parameter[0]\n",
    "    theta = parameter[1]\n",
    "\n",
    "    sigma_points = 0.10\n",
    "    npoints = 100\n",
    "    points = []\n",
    "    for _ in range(npoints):\n",
    "        x = r * np.cos(theta) + sigma_points * np.random.randn()\n",
    "        y = r * np.sin(theta) + sigma_points * np.random.randn()\n",
    "        points.append([x, y])\n",
    "    points = np.array(points)\n",
    "\n",
    "    nx = 32\n",
    "    ny = 32\n",
    "    sigma_image = 0.20\n",
    "    I = np.zeros((nx, ny))\n",
    "    for point in points:\n",
    "        pi = int((point[0] - (-1)) / ((+1) - (-1)) * nx)\n",
    "        pj = int((point[1] - (-1)) / ((+1) - (-1)) * ny) \n",
    "        if (pi < nx) and (pj < ny):   \n",
    "            I[pi, pj] = 1\n",
    "    I = I + sigma_image * np.random.rand(nx, ny)    \n",
    "    I = I.T\n",
    "    I = I.reshape(1,-1)\n",
    "    I = torch.tensor(I, dtype=torch.get_default_dtype())\n",
    "\n",
    "    if return_points:\n",
    "        return I, points\n",
    "    else:\n",
    "        return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows an example of the output of the simulator when $r = 0.70$ and $\\theta = \\pi/4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate samples\n",
    "true_parameter = torch.tensor([0.70, np.pi/4])\n",
    "x_observed, x_points = simulator_model(true_parameter, return_points=True)\n",
    "\n",
    "# plot the observation\n",
    "fig, ax = plt.subplots(facecolor='white', figsize=(11.15, 5.61), ncols=2, constrained_layout=True)\n",
    "circle = plt.Circle((0, 0), 1.0, color='k', ls='--', lw=0.8, fill=False)\n",
    "ax[0].add_artist(circle)\n",
    "ax[0].scatter(x_points[:,0], x_points[:,1], s=20)\n",
    "ax[0].set_xlabel('x')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].set_xlim(-1, +1)\n",
    "ax[0].set_xticks([-1, 0.0, +1.0])\n",
    "ax[0].set_ylim(-1, +1)\n",
    "ax[0].set_yticks([-1, 0.0, +1.0])\n",
    "ax[0].set_title(r'original simulated points with $r = 0.70$ and $\\theta = \\pi/4$')\n",
    "ax[1].imshow(x_observed.view(32, 32), origin='lower', cmap='gray')\n",
    "ax[1].set_xticks([]); ax[1].set_yticks([])\n",
    "ax[1].set_title('noisy observed data (gray image with 32 x 32 pixels)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an `embedding_net`\n",
    "\n",
    "An inference procedure applied to the output data from this simulator model determines the posterior distribution of $r$ and $\\theta$ given an observation of $x$, which lives in a 1024 dimensional space (32 x 32 = 1024). To avoid working directly on these high-dimensional vectors, one can use a convolutional neural network (CNN) that takes the 32x32 images as input and encodes them into 8-dimensional feature vectors. This CNN is trained along with the neural density estimator of the inference procedure and serves as an automatic summary statistics extractor. \n",
    "\n",
    "We define and instantiate the CNN as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryNet(nn.Module): \n",
    "    \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        # 2D convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        # Maxpool layer that reduces 32x32 image to 4x4\n",
    "        self.pool = nn.MaxPool2d(kernel_size=8, stride=8)\n",
    "        # Fully connected layer taking as input the 6 flattened output arrays from the maxpooling layer\n",
    "        self.fc = nn.Linear(in_features=6*4*4, out_features=8) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 6*4*4)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "embedding_net = SummaryNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inference procedure\n",
    "\n",
    "With the `embedding_net` defined and instantiated, we can follow the usual workflow of an inference procedure in `sbi`. The `embedding_net` object appears as an input argument when instantiating the neural density estimator with `utils.posterior_nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set prior distribution for the parameters \n",
    "prior = utils.BoxUniform(low=torch.tensor([0.0, 0.0]), \n",
    "                             high=torch.tensor([1.0, 2*np.pi]))                           \n",
    "\n",
    "# make a SBI-wrapper on the simulator object for compatibility\n",
    "simulator_wrapper, prior = inference.prepare_for_sbi(simulator_model, prior)\n",
    "\n",
    "# instantiate the neural density estimator\n",
    "neural_posterior = utils.posterior_nn(model='maf', \n",
    "                                      embedding_net=embedding_net,\n",
    "                                      hidden_features=10,\n",
    "                                      num_transforms=2)\n",
    "\n",
    "# setup the inference procedure with the SNPE-C procedure\n",
    "inference = inference.SNPE(simulator_wrapper, prior, \n",
    "                           density_estimator=neural_posterior, \n",
    "                           show_progress_bars=True)\n",
    "\n",
    "# run the inference procedure on one round and 10000 simulated data points\n",
    "posterior = inference(num_simulations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n",
    "\n",
    "We now generate 50000 samples of the posterior distribution of $r$ and $\\theta$ when observing an input data point $x$ generated from the `simulator model` with $r = 0.70$ and $\\theta = \\pi/4$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate posterior samples\n",
    "true_parameter = torch.tensor([0.70, np.pi/4])\n",
    "x_observed = simulator_model(true_parameter)\n",
    "samples = posterior.set_default_x(x_observed).sample((50000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows the statistics of the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure\n",
    "fig, ax = utils.pairplot(samples, \n",
    "                             points=true_parameter,\n",
    "                             labels=['r', r'$\\theta$'], \n",
    "                             limits=[[0, 1], [0, 2*np.pi]],\n",
    "                             points_colors='r',\n",
    "                             points_offdiag={'markersize': 6},\n",
    "                             fig_size=[7.5, 6.4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
